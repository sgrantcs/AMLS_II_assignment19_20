{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "#import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID        int64\n",
      "topic    object\n",
      "label    object\n",
      "tweet    object\n",
      "dtype: object\n",
      "                   ID        topic     label  \\\n",
      "0  675847244747177984  amy schumer  negative   \n",
      "1  672827854279843840  amy schumer  negative   \n",
      "2  662755012129529858  amy schumer  negative   \n",
      "3  671502639671042048  amy schumer  negative   \n",
      "4  677359143108214784  amy schumer  negative   \n",
      "5  663714752162607104  amy schumer  negative   \n",
      "6  671468325617033216  amy schumer  negative   \n",
      "7  665033491445383168  amy schumer  negative   \n",
      "8  678882295349190656  amy schumer  negative   \n",
      "9  672070053509079040  amy schumer  negative   \n",
      "\n",
      "                                               tweet  \n",
      "0  @dani_pitter I mean I get the hype around JLaw...  \n",
      "1  Amy Schumer at the #GQmenoftheyear2015 party i...  \n",
      "2  Amy Schumer is on Sky Atlantic doing one of th...  \n",
      "3  Amy Schumer may have brought us Trainwreck, bu...  \n",
      "4  I just think that sports are stupid &amp;anyon...  \n",
      "5  If you do like Amy Schumer, I hope you went &a...  \n",
      "6  People are like, \"Amy Schumer? I don't like he...  \n",
      "7  Seriously though, somebody posted Amy Schumer ...  \n",
      "8  They may be mean but I guess they're not stupi...  \n",
      "9  This Amy Schumer segment is now old news about...  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_table('SemEval2017-task4-dev.subtask-BD.english.INPUT.txt', index_col=False, header =0, sep='\\t', names=['ID','topic','label','tweet'])\n",
    "print(data.dtypes)\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "#    print(pattern, input_txt)\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "  \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Twitter handle\n",
    "data['tidy_tweet'] = np.vectorize(remove_pattern)(data['tweet'], \"@[\\w]*\")\n",
    "#Removing Punctuations, Numbers, and Special Characters\n",
    "data['tidy_tweet'] = data['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "#Removing short words of 3 letters and less\n",
    "data['tidy_tweet'] = data['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "#Tokenizing - TO DO: you can also use NLTK library for this\n",
    "tokenized_tweet = data['tidy_tweet'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming \n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "data['tidy_tweet'] = tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 558)\t1\n",
      "  (0, 428)\t3\n",
      "  (0, 516)\t1\n",
      "  (0, 475)\t1\n",
      "  (0, 921)\t1\n",
      "  (0, 759)\t1\n",
      "  (1, 759)\t1\n",
      "  (1, 641)\t1\n",
      "  (1, 254)\t1\n",
      "  (1, 680)\t1\n",
      "  (1, 391)\t1\n",
      "  (1, 423)\t2\n",
      "  (2, 759)\t1\n",
      "  (2, 979)\t1\n",
      "  (2, 829)\t1\n",
      "  (2, 780)\t1\n",
      "  (2, 769)\t1\n",
      "  (2, 767)\t1\n",
      "  (3, 475)\t1\n",
      "  (3, 759)\t1\n",
      "  (3, 115)\t1\n",
      "  (3, 974)\t1\n",
      "  (4, 516)\t1\n",
      "  (4, 475)\t1\n",
      "  (4, 759)\t1\n",
      "  :\t:\n",
      "  (10546, 235)\t1\n",
      "  (10546, 356)\t1\n",
      "  (10546, 301)\t1\n",
      "  (10546, 561)\t1\n",
      "  (10546, 534)\t1\n",
      "  (10546, 388)\t1\n",
      "  (10546, 999)\t1\n",
      "  (10547, 423)\t1\n",
      "  (10547, 383)\t1\n",
      "  (10547, 193)\t1\n",
      "  (10547, 183)\t1\n",
      "  (10547, 535)\t1\n",
      "  (10547, 999)\t1\n",
      "  (10548, 892)\t1\n",
      "  (10548, 949)\t1\n",
      "  (10548, 67)\t1\n",
      "  (10548, 386)\t1\n",
      "  (10548, 398)\t1\n",
      "  (10548, 112)\t1\n",
      "  (10548, 999)\t1\n",
      "  (10549, 423)\t1\n",
      "  (10549, 374)\t1\n",
      "  (10549, 609)\t1\n",
      "  (10549, 939)\t1\n",
      "  (10549, 999)\t1\n"
     ]
    }
   ],
   "source": [
    "#Create bag-of-words feature\n",
    "bow_vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "# bag-of-words feature matrix\n",
    "bow = bow_vectorizer.fit_transform(data['tidy_tweet'])\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bow = bow[:20632,:]\n",
    "test_bow = bow[20632:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "10545    1\n",
      "10546    1\n",
      "10547    1\n",
      "10548    1\n",
      "10549    1\n",
      "Name: n_label, Length: 10550, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data['n_label'] = data['label'].str.replace(\"positive\", \"1\")\n",
    "data['n_label'] = data['n_label'].str.replace(\"negative\", \"0\")\n",
    "print(data['n_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set (70:30)\n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, data['n_label'], random_state=42, test_size=0.3)\n",
    "# Train a Naive Bayes Multinomial classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(xtrain_bow, ytrain)\n",
    "# making predictions on the testing set \n",
    "y_pred = classifier.predict(xvalid_bow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes model accuracy(in %): 85.65560821484992\n",
      "Multinomial Naive Bayes model precision(in %): 89.93125758188435\n",
      "Multinomial Naive Bayes model F1 score (in %): 90.73847409220727\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(\"Multinomial Naive Bayes model accuracy(in %):\", metrics.accuracy_score(yvalid, y_pred)*100)\n",
    "print(\"Multinomial Naive Bayes model precision(in %):\", metrics.precision_score(yvalid, y_pred, pos_label='1')*100)\n",
    "print(\"Multinomial Naive Bayes model F1 score (in %):\", metrics.f1_score(yvalid, y_pred, pos_label='1')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'positive' 'positive' ... 'positive' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'positive': 2473, 'negative': 692})\n",
      "2473\n",
      "0.7813586097946288\n",
      "The number of positives based on CC approach is 0.7813586097946288.\n"
     ]
    }
   ],
   "source": [
    "#Classify and count tweet quantifier method\n",
    "count = (Counter(y_pred))\n",
    "#print(count)\n",
    "#pos counts \"positive\" labels in the y_pred array\n",
    "pos = count['positive']\n",
    "#neg counts \"negative\" labels in the y_pred array\n",
    "neg = count['negative']\n",
    "#print(pos)\n",
    "cc = pos/(pos + neg)\n",
    "print(cc)    \n",
    "print(\"The number of positives based on CC approach is \"+ str(cc) + \".\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915603128859613 0.3383152173913043\n"
     ]
    }
   ],
   "source": [
    "#compare yvalid and y_pred to establish the share of true positives and false positives\n",
    "#calculate confusion matrix\n",
    "confusion_matrix(yvalid, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(yvalid, y_pred).ravel()\n",
    "(tn, fp, fn, tp)\n",
    "#calculate tpr and fpr by using the above elements of the confusion matrix\n",
    "tpr = tp/(tp + fn)\n",
    "fpr = fp/(fp + tn)\n",
    "print(tpr, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7674565560821486\n"
     ]
    }
   ],
   "source": [
    "#Quantify using Adjusted Count method\n",
    "ac = (cc - fpr)/(tpr - fpr)\n",
    "print(str(ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
